from model.base import MLP, CirConv1dfrom model.gnn import GNN, MyGATfrom torch import nnimport torchimport torch.nn.functional as Ffrom utils.general import prodfrom utils.torch_extension import my_bn# from torch.nn.modules import BatchNorm1dimport mathimport numpy as npimport config as cfgimport timefrom torch.autograd import Variablefrom itertools import chain, combinations, permutationsclass GRUX(nn.Module):    def __init__(self, dim_in, dim_hid, bias=True):        super(GRUX, self).__init__()        self.hidden = nn.ModuleList([            nn.Linear(dim_hid, dim_hid, bias)            for _ in range(3)        ])        self.input = nn.ModuleList([            nn.Linear(dim_in, dim_hid, bias)            for _ in range(3)        ])    def forward(self, inputs, hidden, state=None):        r = torch.sigmoid(self.input[0](inputs) + self.hidden[0](hidden))        z = torch.sigmoid(self.input[1](inputs) + self.hidden[1](hidden))        n = torch.tanh(self.input[2](inputs) + r * self.hidden[2](hidden))        if state is None:            state = hidden        output = (1 - z) * n + z * state        return outputclass TripleMLP(nn.Module):    """Three-layer fully-connected ELU net with batch norm."""    def __init__(self, n_in, n_hid, n_out, do_prob=0.):        super(TripleMLP, self).__init__()        self.fc1 = nn.Linear(n_in, n_hid)        self.fc2 = nn.Linear(n_hid, n_hid)        self.fc3 = nn.Linear(n_hid, n_out)        self.bn1 = nn.BatchNorm1d(n_hid)        # added        self.bn2 = nn.BatchNorm1d(n_hid)        #self.bn3 = nn.BatchNorm1d(n_out)        self.dropout_prob = do_prob        # self.init_weights()    def init_weights(self):        for m in self.modules():            if isinstance(m, nn.Linear):                nn.init.xavier_normal_(m.weight.data)                m.bias.data.fill_(0.1)            elif isinstance(m, nn.BatchNorm1d):                m.weight.data.fill_(1)                m.bias.data.zero_()    def batch_norm(self, inputs, bn):        x = inputs.view(prod(inputs.shape[:-1]), -1)        x = bn(x)        return x.view(*inputs.shape[:-1], -1)    def forward(self, inputs):        # Input shape: [num_sims, num_things, num_features]        x = F.elu(self.fc1(inputs))        # added        x = self.batch_norm(x, self.bn1)        x = F.dropout(x, self.dropout_prob, training=self.training)        x = F.elu(self.fc2(x))        # added        x = self.batch_norm(x, self.bn2)        x = F.dropout(x, self.dropout_prob, training=self.training)        x = self.fc3(x)        # added        #x = self.batch_norm(x, self.bn3)        # x = F.dropout(x, self.dropout_prob, training=self.training)        return xclass states_predict(GNN):    def __init__(self, agent_in, context_hid, edge_type, do_prob=0., skip_first=False):        super(states_predict, self).__init__()        self.agent_in = agent_in        self.agent_hid = cfg.agent_dec_hid        self.edge_type = cfg.edge_types        self.edge_hid = cfg.edge_update_hid        self.context_hid = context_hid        self.modal_num = cfg.dec_modal        self.dropout_prob = do_prob        self.skip_first = skip_first        self.edge_update = nn.ModuleList([TripleMLP(2 * self.agent_hid, self.edge_hid, self.edge_hid)                                          for _ in range(self.edge_type)])        self.node_gru1 = GRUX(self.agent_in + self.context_hid, self.agent_hid)        self.node_gru2 = GRUX(self.agent_hid, self.agent_hid)        self.Gau_weight = nn.ModuleList([nn.Sequential(nn.Linear(self.agent_hid, self.agent_hid), nn.ReLU(), nn.Dropout(do_prob),                                                       nn.Linear(self.agent_hid, 1), nn.ReLU())                                         for _ in range(self.modal_num)])        self.out = nn.ModuleList([TripleMLP(self.agent_hid, self.agent_hid, self.agent_in)                                  for _ in range(self.modal_num)])    def init_weights(self):        for m in self.modules():            if isinstance(m, nn.Linear):                nn.init.xavier_normal_(m.weight.data)                m.bias.data.fill_(0.1)    def select_modal(self, agent_hidden, dis_prob):        """        distribution_pro: [modal_num, node, batch]        return: select idx (from all modal)        """        modal_num, node, batch = dis_prob.shape        #idx_result = Variable(torch.zeros(node, batch))        #dis_prob = dis_weight / dis_sum #[modal_num, node, batch]        '''        dis_prob = dis_prob.permute(1, 2, 0) #[node, batch, modal_num]        dis_label = Variable(torch.zeros(node, batch, modal_num))        for i in range(modal_num):            dis_label[:, :, i] = i        #select modes according to probabilities        for i in range(node):            for j in range(batch):                x = random.uniform(0, 1)                cumulative_probability = 0.0                for item, item_probability in zip(dis_label[i][j], dis_prob[i][j]):                    cumulative_probability += item_probability                    if x < cumulative_probability:                        break                idx_result[i][j] = item          '''        dis_prob = dis_prob.view(modal_num, -1).t()        idx_result = torch.multinomial(dis_prob, 1).t().view(node, batch)        #print("idx_res=", idx_result)        idx = [idx_result == i for i in range(self.modal_num)]        agent_out = Variable(torch.zeros(agent_hidden.size(0), agent_hidden.size(1), self.agent_in).cuda(agent_hidden.device))        #if agent_hidden.is_cuda:            #agent_out = agent_out.cuda()        for m, index in zip(range(self.modal_num), idx):            x_select = agent_hidden[index]            if x_select.shape[0] == 0:                continue            # gru_hidden2: [this_cat_num,  agent_hid]            # x_cat_emb = gru_hidden2.squeeze(1).contiguous()            agent_out[index] = self.out[m](x_select)        return agent_out    def single_predict(self, inputs, es, relations, context_hidden, gru_hidden1, gru_hidden2):        """        inputs: [node, batch, dim]        relations: [E, batch, dim(K)]        gru_hidden1ã€2: [node, batch, dim(gru_hid)]        context_hidden: [batch, dim(context_hid)]        return: predict_state [node, batch, dim]        """        # node2edge        #gnn_h = gru_hidden2.transpose(0, 1)        msg, col, size = self.message(gru_hidden2, es) # msg:[E, batch, dim(gru_hid * 2)]        idx = 1 if self.skip_first else 0        norm = self.edge_type        if self.skip_first:            norm -= 1        #z = relations.repeat(x.size(2), 1, 1, 1).permute(1, 2, 0, 3).contiguous()        edge_hidden = sum(self.edge_update[i](msg) * torch.select(relations, -1, i).unsqueeze(-1) / norm #[E, batch, dim(edge_hid)]                          for i in range(idx, self.edge_type))        #edge2node        context_hidden = context_hidden.unsqueeze(0).contiguous()        context_hidden = context_hidden.repeat(size, 1, 1)        agent_aggregate = self.aggregate(edge_hidden, col, size) #[node, batch, dim(edge_hid)]        gru_hidden1 = self.node_gru1(torch.cat([inputs, context_hidden], dim=-1), agent_aggregate, gru_hidden1)        gru_hidden2 = self.node_gru2(gru_hidden1, gru_hidden2) #[node, batch, dim(agent_hid)]        # multi-modal        distribution_weight = Variable(torch.zeros(self.modal_num, gru_hidden2.size(0), gru_hidden2.size(1)).cuda(inputs.device))        dis_weight_sum = Variable(torch.zeros(gru_hidden2.size(0), gru_hidden2.size(1)).cuda(inputs.device))        for i in range(self.modal_num):            distribution_weight[i] = self.Gau_weight[i](gru_hidden2).squeeze(-1).contiguous()            # dis_weight_sum += distribution_weight[i]        dis_prob = torch.softmax(distribution_weight, dim=0)        # dis_prob = distribution_weight / dis_weight_sum  # [modal_num, node, batch]        agent_out = self.select_modal(gru_hidden2, dis_prob)  #[node,batch,dim(agent_in)]        pred = inputs + agent_out        return pred, gru_hidden1, gru_hidden2    def forward(self, states, infer_relations, context_hidden, group_index, gru_hidden1=None, gru_hidden2=None, burn_in_flag=True):        """        input(which mean agent-node) : [batch_size, step(time_window), node_num, dim]        context_hidden : [batch_size, dim(context_hid)]        infer_relations : [E, batch_size, dim]        """        inputs = torch.tensor(states, dtype=torch.float32).cuda(states.device)        size = inputs.shape[2]        es = np.array(list(permutations(range(size), 2))).T        es = torch.LongTensor(es)        if inputs.is_cuda:            es = es.cuda(states.device)            context_hidden = context_hidden.cuda(states.device)        # x:[node, batch, step, dim]        x = inputs.permute(2, 0, 1, -1).contiguous()        # assert (predict_steps <= x.shape[2])        if gru_hidden1 is None:            gru_hidden1 = Variable(torch.zeros(x.size(0), x.size(1), self.agent_hid).cuda(states.device))            gru_hidden2 = Variable(torch.zeros(x.size(0), x.size(1), self.agent_hid).cuda(states.device))        predict_result = []        if group_index == 0:            predict_step = x.size(2)-1        else:            predict_step = x.size(2)        for step in range(0, predict_step):            '''            if burn_in:                if step <= burn_in_steps:                    predict_in = x[:, :, step, :]                else:                    predict_in = predict_result[step-1]            else:                if not step % predict_steps:                    predict_in = x[:, :, step, :]                else:                    predict_in = predict_result[step - 1]            '''            if burn_in_flag:                predict_in = x[:, :, step, :]            else:                if step == 0:                    predict_in = x[:, :, -1, :]                else:                    predict_in = predict_result[-1]            predict_next, gru_hidden1, gru_hidden2 = self.single_predict(predict_in, es, infer_relations,                                                                         context_hidden, gru_hidden1, gru_hidden2)            predict_result.append(predict_next)        predict_out = torch.stack(predict_result, dim=1) #[node, step, batch, dim]        predict_out = predict_out.permute(2, 1, 0, -1).contiguous() #[batch, step, node, dim]        return predict_out, gru_hidden1, gru_hidden2